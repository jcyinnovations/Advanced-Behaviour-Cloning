{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.local import LocallyConnected2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.applications import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "from TrainSimulator import downsample_zeros, prepare_data, create_datasets, gen\n",
    "from ImageProcessing import data_binning, transform_image, get_viewport, image_gradient, image_flip\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "########################################################################\n",
    "# Simple Model\n",
    "########################################################################\n",
    "def simple_model(shape, n_classes):\n",
    "    activation = 'relu'\n",
    "    #Create the classifier\n",
    "    classifier = Sequential()\n",
    "    #Convolutional Layer\n",
    "    classifier.add(Conv2D(16,1,1, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block0_conv0', \n",
    "                                 input_shape=shape[1:]))\n",
    "    \n",
    "    classifier.add(Conv2D(32,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block1_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(AveragePooling2D(pool_size=(2,2), name='block1_pool'))\n",
    "    \n",
    "    classifier.add(Conv2D(64,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block2_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(AveragePooling2D(pool_size=(2,2), name='block2_pool'))\n",
    "    classifier.add(Dropout(0.25))  \n",
    "    \n",
    "    classifier.add(Conv2D(128,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block3_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(AveragePooling2D(pool_size=(4,4), name='block3_pool'))\n",
    "    classifier.add(Dropout(0.50)) \n",
    "    \n",
    "    classifier.add(Conv2D(128,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block4_conv1'))\n",
    "    \n",
    "    classifier.add(Flatten(name=\"fc_flatten\"))\n",
    "    # Classifier Layer\n",
    "    '''\n",
    "    classifier.add(Dense(256, kernel_initializer='he_normal', name='fc_256'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    \n",
    "    classifier.add(Dense(128, kernel_initializer='glorot_normal', name='fc_256'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    '''\n",
    "    classifier.add(Dense(n_classes, \n",
    "                         kernel_initializer='he_normal', \n",
    "                         activation='softmax', \n",
    "                         name='fc_output'))\n",
    "    classifier.summary()\n",
    "    return classifier\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Direct Drive Model: Take Advantage of SoftPlus activation \n",
    "# characteristics (-1, +1 range) to generate steering angles directly.\n",
    "# Single Neuron output\n",
    "########################################################################\n",
    "def direct_drive_model(shape, n_classes=1):\n",
    "    activation = 'relu'\n",
    "    #activation = 'tanh'\n",
    "    #Create the classifier\n",
    "    classifier = Sequential()\n",
    "    #Convolutional Layer\n",
    "    classifier.add(Conv2D(16,1,1, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block0_conv0', \n",
    "                                 input_shape=shape[1:]))\n",
    "    \n",
    "    classifier.add(Conv2D(32,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block1_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2), name='block1_pool'))\n",
    "    \n",
    "    classifier.add(Conv2D(64,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block2_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2,2), name='block2_pool'))\n",
    "    classifier.add(Dropout(0.25))  \n",
    "    \n",
    "    classifier.add(Conv2D(128,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block3_conv1'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(MaxPooling2D(pool_size=(4,4), name='block3_pool'))\n",
    "    classifier.add(Dropout(0.50)) \n",
    "    \n",
    "    classifier.add(Conv2D(128,3,3, kernel_initializer='glorot_normal',  \n",
    "                                 border_mode='same', \n",
    "                                 name='block4_conv1'))\n",
    "    \n",
    "    classifier.add(Flatten(name=\"fc_flatten\"))\n",
    "    # Classifier Layer\n",
    "    '''\n",
    "    classifier.add(Dense(256, kernel_initializer='he_normal', name='fc_256'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    \n",
    "    classifier.add(Dense(128, kernel_initializer='glorot_normal', name='fc_128'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(Dropout(0.25))\n",
    "    '''\n",
    "    classifier.add(Dense(n_classes, \n",
    "                         kernel_initializer='he_normal', \n",
    "                         activation='softsign', \n",
    "                         name='fc_output'))\n",
    "    classifier.summary()\n",
    "    return classifier\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# AlexNet derivative\n",
    "########################################################################\n",
    "def ak_cifar10_model(shape, n_classes):\n",
    "    activation = 'relu'\n",
    "    classifier = Sequential()\n",
    "    \n",
    "    #Convolutional Layers\n",
    "    classifier.add(Conv2D(64,(5,5), \n",
    "                          padding='same', name='conv_1', \n",
    "                          input_shape=shape[1:], \n",
    "                          kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv_pool_1'))\n",
    "    classifier.add(BatchNormalization(trainable=True))\n",
    "    \n",
    "    classifier.add(Conv2D(64,(5,5), \n",
    "                          padding='same', \n",
    "                          name='conv_2', \n",
    "                          kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), name='conv_pool_2'))\n",
    "    \n",
    "    classifier.add(LocallyConnected2D(64,(3,3), name='lc_1', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "\n",
    "    classifier.add(LocallyConnected2D(64,(3,3), name='lc_2', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "\n",
    "    classifier.add(LocallyConnected2D(64,(2,2), name='lc_2', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "\n",
    "    classifier.add(Flatten(name=\"fc_flatten\"))\n",
    "    \n",
    "    # Classifier Layer\n",
    "    '''\n",
    "    classifier.add(Dense(64, name='fc_1', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(BatchNormalization())\n",
    "    \n",
    "    classifier.add(Dense(128, name='fc_2', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation(activation))\n",
    "    classifier.add(BatchNormalization())\n",
    "    \n",
    "    classifier.add(Dense(256, name='fc_3'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation(activation))\n",
    "    '''\n",
    "    classifier.add(Dense(n_classes, name='fc_out', kernel_initializer='glorot_normal'))\n",
    "    classifier.add(Activation('softmax'))\n",
    "    classifier.summary()\n",
    "    #Save Model architecture to JSON\n",
    "    model_json = classifier.to_json()\n",
    "    with open(\"model_architecture.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "    #for layer in classifier.layers:\n",
    "    #    print(\"Layer {0} Trainable {1}\".format(layer.name, layer.trainable))\n",
    "    return classifier\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Final Combined model: Inception V3 + Classifier\n",
    "########################################################################\n",
    "def combined_model_inception(shape, n_classes):\n",
    "    #Load Inception without FC layers and add AveragePooling\n",
    "    #input_tensor = Input(shape=shape[1:])\n",
    "    inceptionv3 = InceptionV3(input_shape=shape[1:], include_top=False)\n",
    "    x = inceptionv3.output\n",
    "    x = AveragePooling2D((2,2), name='inceptionv3_pool')(x)\n",
    "    inceptionv3 = Model(inceptionv3.input, x)\n",
    "    # i.e. freeze all Inception convolutional layers\n",
    "    for inception_layer in inceptionv3.layers:\n",
    "        inception_layer.trainable = False\n",
    "    \n",
    "    #Create the classifier\n",
    "    classifier = Sequential()\n",
    "    flatten_layer = Flatten(input_shape=inceptionv3.output_shape[1:])\n",
    "    flatten_layer(x)\n",
    "    classifier.add(flatten_layer)\n",
    "    classifier.add(Dense(1024, init='normal', activation='relu', name='fc_1024'))\n",
    "    #classifier.add(Dense(256, init='normal', activation='relu', name='fc_256'))\n",
    "    classifier.add(Dense(n_classes, init='normal', activation='softmax', name='fc_output'))\n",
    "    #Combined Model\n",
    "    model = Model(inceptionv3.input, classifier.output)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Train the classifier\n",
    "########################################################################\n",
    "def train_classifier_original(model, x_train, y_train, x_val, y_val, n_classes, batch, epochs):\n",
    "    # Compile and train the model here.\n",
    "    train_gen = gen(x_train, y_train, batch, n_classes)\n",
    "    val_gen = gen(x_val, y_val, batch, n_classes)\n",
    "    #Expect the generator to create 4 additional views from each image\n",
    "    samples    = 2*len(x_train)\n",
    "    val_samples= 2*len(x_val)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    history = model.fit_generator(train_gen(), \n",
    "                                  samples_per_epoch=samples, \n",
    "                                  nb_epoch=epochs, \n",
    "                                  verbose=1, \n",
    "                                  validation_data=val_gen(), \n",
    "                                  nb_val_samples=val_samples)\n",
    "    model.save_weights('model_weights.h5')\n",
    "    model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "# Convert steering angles to range of non-negative integers: 0 to (n_classes-1)\n",
    "# Steering angles are in range -1 to +1\n",
    "##############################################################################################\n",
    "def scale_labels(y_data, n_classes):\n",
    "    scaled_data = None\n",
    "    if n_classes%2 > 0:\n",
    "        scale = (n_classes-1)/2\n",
    "        scaled_data = np.round(y_data*scale + scale)\n",
    "    else:\n",
    "        scale = n_classes/2\n",
    "        scaled_data = np.round(y_data*scale)\n",
    "    return scaled_data\n",
    "\n",
    "##############################################################################################\n",
    "# Normalize batch of image with sample means\n",
    "##############################################################################################\n",
    "def preprocess_image_batch(x, means):\n",
    "    if means is None:\n",
    "        x = x/255 - 0.5\n",
    "    else:\n",
    "        x = x.astype(\"float32\")\n",
    "        #x = x[:, :, :, ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        r_mean, g_mean, b_mean = means[0], means[1], means[2]\n",
    "        x[:, :, :, 0] -= r_mean\n",
    "        x[:, :, :, 1] -= g_mean\n",
    "        x[:, :, :, 2] -= b_mean\n",
    "    return x\n",
    "\n",
    "########################################################################\n",
    "# Logits for training data\n",
    "########################################################################\n",
    "def sample_logits(data):\n",
    "    # Generate mean, std across all training data for future sample normalization\n",
    "    sample_means = np.zeros(3)\n",
    "    sample_means[0] = np.mean(data[:, :, :, 0])\n",
    "    sample_means[1] = np.mean(data[:, :, :, 1])\n",
    "    sample_means[2] = np.mean(data[:, :, :, 2])\n",
    "    return sample_means\n",
    "\n",
    "########################################################################\n",
    "# This generator loads images and from disk and generate variants\n",
    "########################################################################\n",
    "def gen(data, labels, batch, n_classes):\n",
    "    #2/3 of images in the batch come from L/R viewports\n",
    "    batch_size = int(batch / 2) \n",
    "    def _f():\n",
    "        start = 0\n",
    "        end = start + batch_size\n",
    "        n = data.shape[0]\n",
    "        while True:\n",
    "            x_batch, y_batch = data[start:end], labels[start:end]\n",
    "            #print(x_batch.shape, y_batch.shape)\n",
    "            #Balance the dataset by flipping samples\n",
    "            flip_image_cache = []\n",
    "            flip_label_cache = []\n",
    "            for img, label in zip(x_batch, y_batch):\n",
    "                img = cv2.flip(img,1)\n",
    "                flip_image_cache = flip_image_cache + [img]\n",
    "                label = -1 * label\n",
    "                flip_label_cache = flip_label_cache + [label]\n",
    "            x_batch = np.append(x_batch, flip_image_cache, axis=0)\n",
    "            y_batch = np.append(y_batch, flip_label_cache)\n",
    "            \n",
    "            #x_batch = preprocess_image_batch(x_batch, means)\n",
    "            # Categorical only necessary for multi-class model\n",
    "            if n_classes > 1:\n",
    "                y_batch = scale_labels(y_batch, n_classes)\n",
    "                y_batch = to_categorical(y_batch, n_classes)\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            if start >= n:\n",
    "                start = 0\n",
    "                end = batch_size\n",
    "            yield (x_batch, y_batch)\n",
    "    return _f\n",
    "\n",
    "# New improved trainer\n",
    "def train_classifier(model, x_train, y_train, x_val, y_val, n_classes, batch=256, epochs=5):\n",
    "    \n",
    "    if n_classes > 1:\n",
    "        loss_function = 'categorical_crossentropy'\n",
    "        metrics = ['accuracy']\n",
    "        monitor_metric = 'val_acc'\n",
    "        filepath = \"./training/weights-improvement-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.hdf5\"\n",
    "    else:\n",
    "        # Direct drive uses softsign activation so train with mse loss\n",
    "        loss_function = 'mse'\n",
    "        metrics = ['mse']\n",
    "        monitor_metric = 'val_loss'\n",
    "        filepath = \"./training/weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "        \n",
    "    model.compile(loss=loss_function, \n",
    "                  optimizer=Adam(lr=0.001), \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    train_gen = gen(x_train, y_train, batch, n_classes)\n",
    "    val_gen = gen(x_val, y_val, batch, n_classes)\n",
    "    samples = 2*len(x_train)//batch - 10\n",
    "    val_samples= 2 #2*len(x_val)//batch\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath, \n",
    "                                 monitor=monitor_metric, \n",
    "                                 verbose=0, \n",
    "                                 save_best_only=True, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.75, \n",
    "                                  patience=2, \n",
    "                                  min_lr=0.0001, \n",
    "                                  mode='min', \n",
    "                                  verbose=0)\n",
    "    callbacks_list = [checkpoint,reduce_lr]\n",
    "    history = model.fit_generator(train_gen(), \n",
    "                                  steps_per_epoch=samples,\n",
    "                                  epochs=epochs,\n",
    "                                  verbose=2,\n",
    "                                  validation_data=val_gen(),\n",
    "                                  validation_steps=val_samples, \n",
    "                                  callbacks=callbacks_list)\n",
    "    model.save_weights('model_weights.h5')\n",
    "    model.save('model.h5')\n",
    "    return\n",
    "\n",
    "\n",
    "#################################################################\n",
    "# MAIN Process\n",
    "#################################################################\n",
    "print('Remote Driving Trainer')\n",
    "mode = 'direct' #simple|ak|inception|direct\n",
    "epochs = 80\n",
    "default_shape = (None,112,112,3)\n",
    "use_prepared_data = True\n",
    "\n",
    "if mode == 'direct':\n",
    "    n_classes = 1\n",
    "    batch = 408\n",
    "else:\n",
    "    n_classes = 51\n",
    "    batch = n_classes*8\n",
    "\n",
    "models = {\n",
    "    'ak':ak_cifar10_model, \n",
    "    'simple':simple_model, \n",
    "    'inception': combined_model_inception, \n",
    "    'direct': direct_drive_model\n",
    "}\n",
    "\n",
    "model_input = {\n",
    "    'ak': (32,32),\n",
    "    'simple': (40,40),\n",
    "    'inception': (139,139), \n",
    "    'direct': (40,40)\n",
    "}\n",
    "\n",
    "print(\"Version 3.00\")\n",
    "print(\"Loading data...\")\n",
    "if use_prepared_data:\n",
    "    data = pickle.load( open( \"./training_data.p\", \"rb\" ) )\n",
    "    x_data, y_data = data['features'], data['labels']\n",
    "else:\n",
    "    file_format = [('center','S64'),('left','S64'),('right','S64'),('steering', 'f8'),('throttle', 'f8')]\n",
    "    metadata = genfromtxt('data/driving_log.csv', dtype=file_format, delimiter=',', skip_header=0, usecols=(0, 1, 2, 3, 4))\n",
    "\n",
    "    print(\"Downsampling distribution to reduce zero bias\")\n",
    "    cleansed = downsample_zeros(metadata)\n",
    "    print(\"Downsampled to {0}\".format(len(cleansed)))\n",
    "\n",
    "    print(\"Preparing data (crop, resize to 80x20 and pickle images Optionally include side cameras...\")\n",
    "    x_data, y_data, xbw_data = prepare_data(cleansed, use_side_views=False, size=model_input[mode])\n",
    "\n",
    "print(\"Preparation done.\")\n",
    "\n",
    "print(\"Generating sample logits for image normalization (mean by color)\")\n",
    "color_means = sample_logits(x_data)\n",
    "print(\"Means \\tRed \\tGreen \\tBlue\")\n",
    "print(\"{0:.2f}\\t{1:.2f}\\t{2:.2f}\".format(color_means[0],color_means[1],color_means[2]))\n",
    "color_means = None\n",
    "x_data = preprocess_image_batch(x_data, color_means)\n",
    "\n",
    "#Split dataset\n",
    "print(\"Generating Full Training, Validation Data\")\n",
    "x_train, y_train, x_val, y_val = create_datasets(x_data, y_data, n_classes=n_classes, test=False)\n",
    "print(\"Training Size:\", len(x_train), \"Validation Size:\", len(x_val))\n",
    "\n",
    "''' '''\n",
    "print(\"Building Classifier...\")\n",
    "shape = (None,) + model_input[mode] + (3,)\n",
    "classifier = models[mode](shape, n_classes=n_classes)\n",
    "       \n",
    "print(\"Training Classifier...\")\n",
    "train_classifier(classifier, \n",
    "                 x_train, \n",
    "                 y_train, \n",
    "                 x_val, \n",
    "                 y_val, \n",
    "                 n_classes=n_classes, \n",
    "                 batch=batch, \n",
    "                 epochs=epochs)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Refine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def retrain_classifier(model, x_train, y_train, x_val, y_val, n_classes, batch=256, epochs=5):\n",
    "    train_gen = gen(x_train, y_train, batch, n_classes)\n",
    "    val_gen = gen(x_val, y_val, batch, n_classes)\n",
    "    samples = 2*len(x_train)//batch\n",
    "    val_samples= 2*len(x_val)//batch\n",
    "    \n",
    "    filepath = \"./training/weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.95, \n",
    "                                  patience=1, \n",
    "                                  min_lr=0.0001, \n",
    "                                  mode='min', \n",
    "                                  verbose=1)\n",
    "    callbacks_list = [checkpoint,reduce_lr]\n",
    "    history = model.fit_generator(train_gen(), \n",
    "                                  steps_per_epoch=samples,\n",
    "                                  epochs=epochs,\n",
    "                                  verbose=2,\n",
    "                                  validation_data=val_gen(),\n",
    "                                  validation_steps=val_samples, \n",
    "                                  callbacks=callbacks_list)\n",
    "    model.save_weights('model_weights_ak.h5')\n",
    "    model.save('model_ak.h5')\n",
    "    return\n",
    "\n",
    "classifier = load_model(\"training-direct/weights-improvement-76-0.0092.hdf5\")\n",
    "print(\"Training Classifier...\")\n",
    "retrain_classifier(classifier, x_train, y_train, x_val, y_val, n_classes=n_classes, batch=batch, epochs=40)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "from keras.models import load_model\n",
    "from ImageProcessing import get_viewport\n",
    "from CameraOperations import show_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from numpy import genfromtxt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_radar(points, expectation, filename=None):\n",
    "    N = len(points)\n",
    "    midpoint = N//2\n",
    "    right = np.pi * midpoint/90\n",
    "    left = -1*right\n",
    "    theta = np.linspace(right, left, N, endpoint=True)\n",
    "    #radii = 10 * np.random.rand(N)\n",
    "    radii = 4*points/np.max(points)\n",
    "    width = np.pi / 90\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111, projection='polar')\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    ax.tick_params(axis='both', which='both', labelbottom='off', labeltop='off', labelleft='off')\n",
    "    #ax.grid(False)\n",
    "    #ax.xaxis.grid(True)\n",
    "    ax.bar(0, 8.0, color=\"black\", width=N*np.pi/90, bottom=0)\n",
    "    bars = ax.bar(theta, radii, width=width, bottom=4)\n",
    "    #Highlight the prediction\n",
    "    #bars[np.argmax(radii)].set_facecolor('red')\n",
    "    #Display Prediction\n",
    "    ax.bar(theta[expectation], 4.5, width=width, bottom=2, color=\"red\")\n",
    "    # Display the limits\n",
    "    #ax.bar(theta[0], 6.5, color=\"black\", width=width/4, bottom=0)\n",
    "    #ax.bar(theta[N-1], 6.5, color=\"black\", width=width/4, bottom=0)\n",
    "    ax.set_axis_bgcolor('lightgray')\n",
    "    #plt.show()\n",
    "    if filename is None:\n",
    "        fig.canvas.draw()\n",
    "        # Now we can save it to a numpy array.\n",
    "        data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        #buf = np.fromstring (fig.canvas.tostring_argb(), dtype=np.uint8 )\n",
    "        data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.clf()\n",
    "        return data\n",
    "    else:\n",
    "        fig.canvas.draw()\n",
    "        fig.savefig(filename, transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "def plot_bar():\n",
    "    return \n",
    "\n",
    "best_model = load_model(\"./training-direct/weights-improvement-21-0.0074.hdf5\")\n",
    "\n",
    "file_format = [('center','S64'),('left','S64'),('right','S64'),('steering', 'f8'),('throttle', 'f8')]\n",
    "records = genfromtxt('data/driving_log.csv', dtype=file_format, delimiter=',', skip_header=0, usecols=(0, 1, 2, 3, 4))\n",
    "\n",
    "size = len(records)\n",
    "choice = np.random.choice(size, 2, replace=False)\n",
    "steering_norm = np.array([s for s in range(51)])\n",
    "\n",
    "for i in range(len(choice)):\n",
    "    filename = \"data/{0}\".format(records[i]['center'].decode(\"utf-8\").strip())\n",
    "    image = mpimg.imread(filename)\n",
    "    test_strip = get_viewport(image, size=(40,40))\n",
    "    feature = test_strip/255 - 0.5\n",
    "    predictions = best_model.predict(feature[None, :], batch_size=1)[0]\n",
    "    expectation = int(round(np.sum(steering_norm*predictions)))\n",
    "    rplot = plot_radar(predictions, expectation, \"radar{0}\".format(i))\n",
    "    #plt.imshow(rplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mpy\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "fps = 25\n",
    "sequence_length = len(records)\n",
    "sequence_start = 0\n",
    "sequence_duration = int(sequence_length/fps) #500/fps #\n",
    "\n",
    "def make_video(t):\n",
    "    idx = sequence_start + int(t / (1/fps))\n",
    "    filename = \"./data/{0}\".format(records['center'][idx].decode(\"utf-8\").strip())\n",
    "    img = mpimg.imread(filename)\n",
    "    # Make steering predictions and plot angle on compass\n",
    "    test_strip = get_viewport(img, size=(40,40))\n",
    "    feature = test_strip/255 - 0.5\n",
    "    predictions = best_model.predict(feature[None, :], batch_size=1)[0]\n",
    "    radar_file = \"data/radar{0}.png\".format(idx)\n",
    "    expectation = int(round(np.sum(steering_norm*predictions)))\n",
    "    plot_radar(predictions, expectation, radar_file)\n",
    "\n",
    "    pil_image = Image.fromarray(img)\n",
    "    new_im = pil_image.resize((img.shape[1]*3, img.shape[0]*3))\n",
    "    radar = Image.open(radar_file)\n",
    "    new_im.paste(radar, (0,0))\n",
    "    return np.asarray(new_im)\n",
    "\n",
    "vid_output = \"training_sample_expectations.mp4\"\n",
    "clip = mpy.VideoClip(make_video, duration=sequence_duration)\n",
    "%time clip.write_videofile(vid_output, fps=fps, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
