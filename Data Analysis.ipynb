{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analyze Simulator Data\n",
    "\n",
    "The first 20 attempts at the self-driving simulator yielded a single success, iteration #10. This attempt used a combination of 16,440 image samples (data provided, 5 laps of track 1, 1 lap of track 2), plus augmented samples based on splitting the viewport into three lateral views: center (main sample), left and right. The left and right viewports were assigned random steering values (normal distribution * 0.5) designed to move the car back to center. \n",
    "\n",
    "This attempt successfully navigated the first corner 9 times out of 10 but resulted in the car weaving back and forth across the road. It also resulted in the model plateauing at around 35% accuracy no matter how much the batch size, epochs were changed. Finally, it was never able to navigate the second corner. The weaving almost looked like the model was replicating the function used to derive the steering angles for the L and R viewports.\n",
    "\n",
    "All subsequent iterations tried to build on this notion by augmenting the data both with up/down sampling and various algorithms designed to adjust the steering based on the viewport. None were successful at even navigating the first corner.\n",
    "\n",
    "This led to a few conclusions:\n",
    "\n",
    "- The fault lay in the data. There were not enough examples of the corner cases (pun intended) to teach the car in general how to navigate turns. Generating data was not the solution, new training data especially for corners was required. Initial sample analysis led to this same conclusion but was ignored because it was thought that augmentation/downsampling could adequately compensate.\n",
    "- The classifier was inadequate to the task. It was a two-layer design trying to learn 201 classes (more on that next) from complex input data. Additional layers (at least 2 more were needed).\n",
    "- The initial use of 201 classes for the feature space (-1.00 to +1.00) was deemed necessary for ultimate resolution in the steering angle output. However, upon furture examination of the steering data that number could be drastically reduced to between 21 and 51. 21 classes would give a resolution of +/-0.05 in the steering angle; 51 classes +/-0.02. This would also have the positive side effect of smoothing the car's motion and consolidating samples for steering. \n",
    "- The choice is 51 classes because this will result in a 1 degree steering resolution\n",
    "- The analysis done previously was insufficient to ensure proper data distribution over various steering angles. New statistical analysis was needed. \n",
    "- The viewport methodology was a good but extreme way of trying to generalize the samples. Increasing the center viewport width to 2/3 of the image width would allow encompassing more information from the view while also allowing for a different upsampling techniqe: dithering through latteral translation while keeping the same steering angle. This would account for varying positions in the lane while avoiding the difficult task of deriving a new steering angle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from ImageProcessing import data_binning\n",
    "from TrainSimulator import *\n",
    "import matplotlib.image as mpimg \n",
    "\n",
    "#Format probabilities in a readable fashion\n",
    "float_formatter = lambda x: \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "file_format = [('center','S64'),('left','S64'),('right','S64'),('steering', 'f8'),('throttle', 'f8')]\n",
    "combined = genfromtxt('data/driving_log.csv', dtype=file_format, delimiter=',', skip_header=0, usecols=(0, 1, 2, 3, 4))\n",
    "\n",
    "#Scale steering and throttle\n",
    "y_data = scale_labels(combined['steering'], n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(y_data))\n",
    "#Augment with left and right cameras\n",
    "cache = []\n",
    "y_data_aug = None\n",
    "mid = (n_classes-1)/2\n",
    "correction = round(0.1 * mid)\n",
    "for row in zip(y_data):\n",
    "    l = row[0] + correction\n",
    "    r = row[0] - correction\n",
    "    if l > mid*2 or r < 0:\n",
    "        print(correction, row[0], l, r)\n",
    "    cache = cache + [l,r]\n",
    "\n",
    "y_data_aug = np.array(cache)\n",
    "y_data_aug = np.append(y_data, y_data_aug)\n",
    "print(len(y_data_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "gs2 = gridspec.GridSpec(2, 3)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "com = plt.subplot(2,3,5)\n",
    "o = plt.hist(y_data, bins=n_classes)\n",
    "t = com.set_title(\"Combined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_data,y_data = downsample(combined['center'], y_data, n_classes, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_means = sample_logits(x_data)\n",
    "print(\"Means \\tRed \\tGreen \\tBlue\")\n",
    "print(sample_means[0],\"\\t\",sample_means[1],\"\\t\",sample_means[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "o = plt.hist(y_data, bins=n_classes)\n",
    "#t = fig.set_title(\"After Downsampling\")\n",
    "print(\"New Mean\", np.mean(y_data), \"Median\", np.median(y_data), \"Count\", len(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video review_clip_track2.mp4\n",
      "[MoviePy] Writing video review_clip_track2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████▉| 3960/3961 [00:10<00:00, 371.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: review_clip_track2.mp4 \n",
      "\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mpy\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "file_format = [('center','S64'),('left','S64'),('right','S64'),('steering', 'f8'),('throttle', 'f8')]\n",
    "dataset = genfromtxt('data/driving_log-flawed-Track2.csv', dtype=file_format, delimiter=',', skip_header=0, usecols=(0, 1, 2, 3, 4))\n",
    "\n",
    "fps = 15\n",
    "sequence_length = len(dataset)\n",
    "sequence_start = 0\n",
    "sequence_duration = int(sequence_length/fps)\n",
    "\n",
    "def make_video(t):\n",
    "    idx = sequence_start + int(t / (1/fps))\n",
    "    filename = \"./data/{0}\".format(dataset['center'][idx].decode(\"utf-8\").strip())\n",
    "    image = cv2.imread(filename)\n",
    "    label = \"{0}\".format(idx)\n",
    "    cv2.putText(image, label,(20,20),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),thickness=2)\n",
    "    return cv2.cvtColor(image.astype(\"uint8\"), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "vid_output = \"review_clip_track2.mp4\"\n",
    "clip = mpy.VideoClip(make_video, duration=sequence_duration)\n",
    "%time clip.write_videofile(vid_output, fps=fps, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(sequence_length):\n",
    "    filename = \"./data/{0}\".format(dataset['center'][i].decode(\"utf-8\").strip())\n",
    "    image = cv2.imread(filename)\n",
    "    if image is None:\n",
    "        print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
